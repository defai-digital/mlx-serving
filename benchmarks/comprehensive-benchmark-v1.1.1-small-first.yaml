# Comprehensive Text Model Benchmark - v1.1.1 Release (Small Models First)
# Start with small models that are likely cached, then move to larger ones

benchmark:
  max_tokens: 100
  temperature: 0.7
  timeout_ms: 300000

models:
  # Very Small Models (0.5B - 1.5B) - Start here
  - name: mlx-community/Qwen2.5-0.5B-Instruct-4bit
    size: 0.5B
    questions: 5
    cycles: 1
    enabled: true

  - name: mlx-community/Llama-3.2-1B-Instruct-4bit
    size: 1B
    questions: 5
    cycles: 1
    enabled: true

  - name: mlx-community/Qwen2.5-1.5B-Instruct-4bit
    size: 1.5B
    questions: 5
    cycles: 1
    enabled: true

  # Small Models (3B - 4B)
  - name: mlx-community/Llama-3.2-3B-Instruct-4bit
    size: 3B
    questions: 5
    cycles: 1
    enabled: true

  - name: mlx-community/Phi-3-mini-4k-instruct-4bit
    size: 3.8B
    questions: 5
    cycles: 1
    enabled: true

  # Medium Models (7B - 8B)
  - name: mlx-community/Qwen2.5-7B-Instruct-4bit
    size: 7B
    questions: 5
    cycles: 1
    enabled: true

  - name: mlx-community/Llama-3.1-8B-Instruct-4bit
    size: 8B
    questions: 5
    cycles: 1
    enabled: true

  # Large Models (14B - 32B)
  - name: mlx-community/Qwen2.5-14B-Instruct-4bit
    size: 14B
    questions: 5
    cycles: 1
    enabled: true

  - name: mlx-community/Qwen2.5-Coder-32B-Instruct-4bit
    size: 30B
    questions: 5
    cycles: 1
    enabled: true

  - name: mlx-community/Qwen2.5-32B-Instruct-4bit
    size: 32B
    questions: 5
    cycles: 1
    enabled: true

  - name: mlx-community/Mixtral-8x7B-Instruct-v0.1-4bit
    size: 47B
    questions: 5
    cycles: 1
    enabled: true

  # Very Large Models (70B - 141B) - Save for last
  - name: mlx-community/Meta-Llama-3.1-70B-Instruct-4bit
    size: 70B
    questions: 5
    cycles: 1
    enabled: true

  - name: mlx-community/Qwen2.5-72B-Instruct-4bit
    size: 72B
    questions: 5
    cycles: 1
    enabled: true

  # Removed: mistral-community/Mixtral-8x22B-Instruct-v0.1-4bit (141B)
  # Reason: BitsAndBytes NF4 quantization incompatibility - MLX expects native 4-bit format
  # See: /Users/akiralam/code/automatosx/tmp/mixtral-8x22b-investigation-report.md

questions:
  - "What is the capital of France?"
  - "Explain quantum computing in simple terms."
  - "Write a haiku about technology."
  - "What are the benefits of exercise?"
  - "How does photosynthesis work?"
